# Udacity-Data-Wrangle-Project

Wrangle Report
There are three parts of the data that I gathered for this project. The main table was read from a local csv file. Then for each tweet id in the main table, I extracted its corresponding information using API and saved the json data to a text file. Next, I selected needed information from the text file and loaded it to a dataframe as the second table. Lastly, I downloaded a tsv file programmatically using request and read it to a dataframe as the third table.

In terms of assessing the three table, I first checked for missing values and datatype of each column. Then I checked for duplicated columns among three tables. Then I realized that records with non-null status are retweets. Same idea applies to the reply columns. There are three columns without expanded urls. Next, I checked the distributions of quantitative variables in all tables. I then looked at specific columns to find out whether those values are reasonable and fit the purpose of the analysis. 

Based on the assessment, I came up with 8 quality issues and 2 tidiness issues for the datasets. In terms of cleaning, I first removed those non-original records and column names indicating those records. Then Replaced None with null for each dog stage and concatenate the dog stage information into one column. To fix erroneous datatypes, I converted tweet_id to string type, timestamp to datetime and dog_stage to category type. The lower-case values in name column are not names, thus I converted those incorrect names to ‘None’. Next, I used regrex to extract appropriate information from source column and fixed the format. I unified the ratings by excluding denominators that are not 10 and dealt with ratings with decimals through extracting ratings from text correctly. Then I collected ratings that are in the range from 7 to 14 inclusively. Lastly, I merged the three tables and dropped duplicated/unneeded columns. 
